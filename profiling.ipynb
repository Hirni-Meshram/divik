{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from divik.cluster import KMeans, DunnDiviK\n",
    "import divik.cluster._kmeans._core\n",
    "import divik.cluster._kmeans._gap\n",
    "import divik.cluster._kmeans._initialization\n",
    "import divik.cluster._divik._dunn\n",
    "import divik.score._sampled_gap\n",
    "import divik.score._gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100000, n_features=100, centers=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = DunnDiviK(distance='euclidean', filter_type='auto', n_jobs=1, features_percentage=0.2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 6.46002 s\n",
       "File: /app/divik/cluster/_kmeans/_core.py\n",
       "Function: __call__ at line 111\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   111                                               def __call__(self, data: Data, number_of_clusters: int) \\\n",
       "   112                                                       -> Tuple[IntLabels, Centroids]:\n",
       "   113         1         11.0     11.0      0.0          _validate_kmeans_input(data, number_of_clusters)\n",
       "   114         1          1.0      1.0      0.0          if number_of_clusters == 1:\n",
       "   115                                                       return np.zeros((data.shape[0], 1), dtype=int), \\\n",
       "   116                                                              np.mean(data, axis=0, keepdims=True)\n",
       "   117         1          9.0      9.0      0.0          data = data.reshape(data.shape, order='C')\n",
       "   118         1          1.0      1.0      0.0          if self.normalize_rows:\n",
       "   119                                                       _validate_normalizable(data)\n",
       "   120                                                       data = normalize_rows(data)\n",
       "   121         1         37.0     37.0      0.0          label_set = np.arange(number_of_clusters)\n",
       "   122         1    6316646.0 6316646.0     97.8          centroids = self.initialize(data, number_of_clusters)\n",
       "   123         1        122.0    122.0      0.0          old_labels = np.nan * np.zeros((data.shape[0],))\n",
       "   124         1      50439.0  50439.0      0.8          labels = self.labeling(data, centroids)\n",
       "   125         2         14.0      7.0      0.0          for _ in range(self.number_of_iterations):\n",
       "   126         2       5070.0   2535.0      0.1              if np.unique(labels).size != number_of_clusters:\n",
       "   127                                                           centroids, labels = self._fix_labels(\n",
       "   128                                                               data, centroids, labels, number_of_clusters)\n",
       "   129         2        659.0    329.5      0.0              if np.all(labels == old_labels):\n",
       "   130         1          2.0      2.0      0.0                  break\n",
       "   131         1          1.0      1.0      0.0              old_labels = labels\n",
       "   132         1      34732.0  34732.0      0.5              centroids = redefine_centroids(data, old_labels, label_set)\n",
       "   133         1      52278.0  52278.0      0.8              labels = self.labeling(data, centroids)\n",
       "   134         1          1.0      1.0      0.0          return labels, centroids\n",
       "\n",
       "Total time: 6.31648 s\n",
       "File: /app/divik/cluster/_kmeans/_initialization.py\n",
       "Function: __call__ at line 99\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    99                                               def __call__(self, data: Data, number_of_centroids: int) -> Centroids:\n",
       "   100         1          4.0      4.0      0.0          _validate(data, number_of_centroids)\n",
       "   101         1    6239253.0 6239253.0     98.8          residuals = _find_residuals(data)\n",
       "   102         1       1279.0   1279.0      0.0          selected = self._get_percentile_element(residuals)\n",
       "   103         1         10.0     10.0      0.0          centroids = np.nan * np.zeros((number_of_centroids, data.shape[1]))\n",
       "   104         1          3.0      3.0      0.0          centroids[0] = data[selected]\n",
       "   105         1         15.0     15.0      0.0          assert not np.any(np.isnan(centroids[0]))\n",
       "   106                                           \n",
       "   107         1        343.0    343.0      0.0          distances = np.inf * np.ones((data.shape[0],))\n",
       "   108        10         12.0      1.2      0.0          for i in range(1, number_of_centroids):\n",
       "   109         9        150.0     16.7      0.0              assert not np.any(np.isnan(centroids[np.newaxis, i - 1]))\n",
       "   110         9         17.0      1.9      0.0              current_distance = dist.cdist(\n",
       "   111         9      59235.0   6581.7      0.9                  data, centroids[np.newaxis, i - 1], self.distance)\n",
       "   112         9        502.0     55.8      0.0              nans = np.isnan(current_distance)\n",
       "   113         9        318.0     35.3      0.0              if np.any(nans):\n",
       "   114                                                           locations_of_nans = np.array(list(zip(*np.nonzero(nans))))\n",
       "   115                                                           raise ValueError('Distances between points cannot be NaN. '\n",
       "   116                                                                            + 'This indicates that your data is probably'\n",
       "   117                                                                            + ' corrupted and analysis cannot be '\n",
       "   118                                                                            + 'continued in this setting. '\n",
       "   119                                                                            + 'Amount of NaNs: {0}. '.format(nans.sum())\n",
       "   120                                                                            + 'At positions described by [spot, '\n",
       "   121                                                                            + 'centroid]: {0}'.format(locations_of_nans))\n",
       "   122         9       3983.0    442.6      0.1              distances[:] = np.minimum(current_distance.ravel(), distances)\n",
       "   123         9      11325.0   1258.3      0.2              selected = self._get_percentile_element(distances)\n",
       "   124         9         31.0      3.4      0.0              centroids[i] = data[selected]\n",
       "   125                                           \n",
       "   126         1          0.0      0.0      0.0          return centroids"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun \\\n",
    "    -f divik.cluster._kmeans._initialization.PercentileInitialization.__call__ \\\n",
    "    -f divik.cluster._kmeans._core._KMeans.__call__ \\\n",
    "    kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:12<00:12, 12.14s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:23<00:00, 11.82s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [00:00<00:01,  6.64it/s]\u001b[A\n",
      " 22%|██▏       | 2/9 [00:00<00:01,  6.88it/s]\u001b[A\n",
      " 33%|███▎      | 3/9 [00:00<00:00,  6.85it/s]\u001b[A\n",
      " 44%|████▍     | 4/9 [00:00<00:00,  6.70it/s]\u001b[A\n",
      " 56%|█████▌    | 5/9 [00:00<00:00,  6.40it/s]\u001b[A\n",
      " 67%|██████▋   | 6/9 [00:00<00:00,  6.17it/s]\u001b[A\n",
      " 78%|███████▊  | 7/9 [00:01<00:00,  5.70it/s]\u001b[A\n",
      " 89%|████████▉ | 8/9 [00:01<00:00,  5.49it/s]\u001b[A\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.43it/s]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.15s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10000/100000 [00:36<05:24, 277.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.95s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20000/100000 [00:43<03:39, 363.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.39s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30000/100000 [00:49<02:27, 474.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:08<00:08,  8.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30000/100000 [01:00<02:27, 474.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40000/100000 [01:01<01:50, 544.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.90s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50000/100000 [01:10<01:17, 645.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.41s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60000/100000 [01:20<00:55, 720.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.40s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70000/100000 [01:31<00:38, 778.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:07<00:07,  7.16s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80000/100000 [01:42<00:24, 805.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.51s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90000/100000 [01:50<00:11, 904.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:11<00:11, 11.14s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:06<00:00, 788.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 126.747 s\n",
       "File: /app/divik/cluster/_divik/_dunn.py\n",
       "Function: dunn_divik at line 25\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    25                                           def dunn_divik(data: Data, selection: np.ndarray,\n",
       "    26                                                          fast_kmeans: GAPSearch, full_kmeans: DunnSearch,\n",
       "    27                                                          feature_selector: StatSelector,\n",
       "    28                                                          minimal_size: int, rejection_size: int, report: DivikReporter) \\\n",
       "    29                                                   -> Optional[DivikResult]:\n",
       "    30        11      70578.0   6416.2      0.1      subset = data[selection]\n",
       "    31                                           \n",
       "    32        11        160.0     14.5      0.0      if subset.shape[0] <= max(full_kmeans.max_clusters, minimal_size):\n",
       "    33                                                   report.finished_for(subset.shape[0])\n",
       "    34                                                   return None\n",
       "    35                                           \n",
       "    36        11        706.0     64.2      0.0      report.filter(subset)\n",
       "    37        11       7319.0    665.4      0.0      feature_selector = clone(feature_selector)\n",
       "    38        11     382818.0  34801.6      0.3      filtered_data = feature_selector.fit_transform(subset)\n",
       "    39        11      21753.0   1977.5      0.0      report.filtered(filtered_data)\n",
       "    40                                           \n",
       "    41        11        150.0     13.6      0.0      report.stop_check()\n",
       "    42        11  124609570.0 11328142.7     98.3      fast_kmeans = clone(fast_kmeans).fit(filtered_data)\n",
       "    43        11         36.0      3.3      0.0      if fast_kmeans.fitted_ and fast_kmeans.n_clusters_ == 1:\n",
       "    44        10      16041.0   1604.1      0.0          report.finished_for(subset.shape[0])\n",
       "    45        10         46.0      4.6      0.0          return None\n",
       "    46                                           \n",
       "    47         1         26.0     26.0      0.0      report.processing(filtered_data)\n",
       "    48         1    1544679.0 1544679.0      1.2      clusterer = clone(full_kmeans).fit(filtered_data)\n",
       "    49         1          3.0      3.0      0.0      partition = clusterer.labels_\n",
       "    50         1       4006.0   4006.0      0.0      _, counts = np.unique(partition, return_counts=True)\n",
       "    51                                           \n",
       "    52         1         42.0     42.0      0.0      if any(counts <= rejection_size):\n",
       "    53                                                   report.rejected(subset.shape[0])\n",
       "    54                                                   return None\n",
       "    55                                           \n",
       "    56         1         27.0     27.0      0.0      report.recurring(len(counts))\n",
       "    57         1          2.0      2.0      0.0      recurse = partial(\n",
       "    58         1          1.0      1.0      0.0          dunn_divik, data=data, fast_kmeans=fast_kmeans,\n",
       "    59         1          1.0      1.0      0.0          full_kmeans=full_kmeans, feature_selector=feature_selector,\n",
       "    60         1          2.0      2.0      0.0          minimal_size=minimal_size, rejection_size=rejection_size,\n",
       "    61         1          4.0      4.0      0.0          report=report)\n",
       "    62         1       4833.0   4833.0      0.0      del subset\n",
       "    63         1       1319.0   1319.0      0.0      del filtered_data\n",
       "    64         1      78770.0  78770.0      0.1      gc.collect()\n",
       "    65                                               subregions = [\n",
       "    66         1          5.0      5.0      0.0          recurse(selection=_recursive_selection(selection, partition, cluster))\n",
       "    67         1       3587.0   3587.0      0.0          for cluster in np.unique(partition)\n",
       "    68                                               ]\n",
       "    69                                           \n",
       "    70         1         30.0     30.0      0.0      report.assemble()\n",
       "    71         1          2.0      2.0      0.0      return DivikResult(clustering=clusterer, feature_selector=feature_selector,\n",
       "    72         1          7.0      7.0      0.0                         merged=partition, subregions=subregions)\n",
       "\n",
       "Total time: 124.39 s\n",
       "File: /app/divik/cluster/_kmeans/_gap.py\n",
       "Function: _fit_kmeans at line 100\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   100                                               def _fit_kmeans(self, n_clusters, data):\n",
       "   101        22      29484.0   1340.2      0.0          kmeans = clone(self.kmeans)\n",
       "   102        22         56.0      2.5      0.0          kmeans.n_clusters = n_clusters\n",
       "   103        22    6916481.0 314385.5      5.6          kmeans.fit(data)\n",
       "   104        22  117443993.0 5338363.3     94.4          idx, std = self._gap(data, kmeans)\n",
       "   105        22         40.0      1.8      0.0          return kmeans, idx, std\n",
       "\n",
       "Total time: 107.849 s\n",
       "File: /app/divik/score/_gap.py\n",
       "Function: _sampled_dispersion at line 28\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    28                                           def _sampled_dispersion(seed: int, sampler: BaseSampler, kmeans: KMeans) \\\n",
       "    29                                                   -> float:\n",
       "    30       240    1148572.0   4785.7      1.1      X = sampler.get_sample(seed)\n",
       "    31       240        900.0      3.8      0.0      if kmeans.normalize_rows:\n",
       "    32                                                   X = normalize_rows(X)\n",
       "    33       240    2470213.0  10292.6      2.3      y = kmeans.fit_predict(X)\n",
       "    34       240     347407.0   1447.5      0.3      clusters = pd.DataFrame(X).groupby(y)\n",
       "    35       240        756.0      3.1      0.0      return float(np.mean([\n",
       "    36       240        411.0      1.7      0.0          np.mean(dist.pdist(cluster_members.values, kmeans.distance))\n",
       "    37       240  103880673.0 432836.1     96.3          for _, cluster_members in clusters\n",
       "    38                                                   if cluster_members.shape[0] != 1\n",
       "    39                                               ]))\n",
       "\n",
       "Total time: 19.4343 s\n",
       "File: /app/divik/score/_sampled_gap.py\n",
       "Function: sampled_gap at line 21\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    21                                           def sampled_gap(data: Data, kmeans: KMeans,\n",
       "    22                                                           sample_size: Union[int, float] = 1000,\n",
       "    23                                                           n_jobs: int = None,\n",
       "    24                                                           seed: int = 0,\n",
       "    25                                                           n_trials: int = 100,\n",
       "    26                                                           return_deviation: bool = False) -> float:\n",
       "    27                                               # TODO: Docs\n",
       "    28         2        240.0    120.0      0.0      data_ = StratifiedSampler(n_rows=sample_size, n_samples=n_trials\n",
       "    29         2          8.0      4.0      0.0                                ).fit(data, kmeans.labels_)\n",
       "    30         2        151.0     75.5      0.0      reference_ = UniformSampler(n_rows=sample_size, n_samples=n_trials\n",
       "    31         2      12467.0   6233.5      0.1                                  ).fit(data)\n",
       "    32         2       1426.0    713.0      0.0      kmeans_ = clone(kmeans)\n",
       "    33         2         62.0     31.0      0.0      seeds = list(seed + np.arange(n_trials) * _BIG_PRIME)\n",
       "    34         2        429.0    214.5      0.0      with data_.parallel() as d, reference_.parallel() as r:\n",
       "    35         2          5.0      2.5      0.0          initializer = partial(_pool_initialize, [d, r])\n",
       "    36         2          3.0      1.5      0.0          with maybe_pool(n_jobs, initializer=initializer,\n",
       "    37         2        121.0     60.5      0.0                          initargs=(d.initargs, r.initargs)) as pool:\n",
       "    38         2          3.0      1.5      0.0              compute_disp = partial(_dispersion, sampler=r, kmeans=kmeans_)\n",
       "    39         2    9285204.0 4642602.0     47.8              ref_disp = pool.map(compute_disp, seeds)\n",
       "    40         2          9.0      4.5      0.0              compute_disp = partial(_dispersion, sampler=d, kmeans=kmeans_)\n",
       "    41         2   10133778.0 5066889.0     52.1              data_disp = pool.map(compute_disp, seeds)\n",
       "    42         2         32.0     16.0      0.0      ref_disp = np.log(ref_disp)\n",
       "    43         2         10.0      5.0      0.0      data_disp = np.log(data_disp)\n",
       "    44         2        111.0     55.5      0.0      gap = np.mean(ref_disp) - np.mean(data_disp)\n",
       "    45         2          2.0      1.0      0.0      result = (gap,)\n",
       "    46         2          2.0      1.0      0.0      if return_deviation:\n",
       "    47         2        223.0    111.5      0.0          std = np.sqrt(np.var(ref_disp) + np.var(data_disp)) / n_trials\n",
       "    48         2          3.0      1.5      0.0          result += (std,)\n",
       "    49         2          2.0      1.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun \\\n",
    "    -f divik.cluster._divik._dunn.dunn_divik \\\n",
    "    -f divik.cluster._kmeans._gap.GAPSearch._fit_kmeans \\\n",
    "    -f divik.score._sampled_gap.sampled_gap \\\n",
    "    -f divik.score._sampled_gap._dispersion \\\n",
    "    mdl.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.964557 s\n",
       "File: /app/divik/cluster/_kmeans/_initialization.py\n",
       "Function: _find_residuals at line 37\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    37                                           def _find_residuals(data: Data) -> np.ndarray:\n",
       "    38         1          2.0      2.0      0.0      features = data.T\n",
       "    39         1          3.0      3.0      0.0      assumed_ys = features[0]\n",
       "    40         1        606.0    606.0      0.1      modelled_xs = np.hstack([np.ones((data.shape[0], 1)),\n",
       "    41         1      31259.0  31259.0      3.2                               features[1:].T])\n",
       "    42         1     925684.0 925684.0     96.0      coefficients = _lstsq_numba(modelled_xs, assumed_ys)\n",
       "    43         1       7000.0   7000.0      0.7      residuals = _residuals_numba(modelled_xs, assumed_ys, coefficients)\n",
       "    44         1          3.0      3.0      0.0      return residuals\n",
       "\n",
       "Total time: 1.09622 s\n",
       "File: /app/divik/cluster/_kmeans/_initialization.py\n",
       "Function: __call__ at line 99\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    99                                               def __call__(self, data: Data, number_of_centroids: int) -> Centroids:\n",
       "   100         1          5.0      5.0      0.0          _validate(data, number_of_centroids)\n",
       "   101         1     971639.0 971639.0     88.6          residuals = _find_residuals(data)\n",
       "   102         1       2261.0   2261.0      0.2          selected = self._get_percentile_element(residuals)\n",
       "   103         1         19.0     19.0      0.0          centroids = np.nan * np.zeros((number_of_centroids, data.shape[1]))\n",
       "   104         1          7.0      7.0      0.0          centroids[0] = data[selected]\n",
       "   105         1         35.0     35.0      0.0          assert not np.any(np.isnan(centroids[0]))\n",
       "   106                                           \n",
       "   107         1        225.0    225.0      0.0          distances = np.inf * np.ones((data.shape[0],))\n",
       "   108        10         22.0      2.2      0.0          for i in range(1, number_of_centroids):\n",
       "   109         9        225.0     25.0      0.0              assert not np.any(np.isnan(centroids[np.newaxis, i - 1]))\n",
       "   110         9         55.0      6.1      0.0              current_distance = dist.cdist(\n",
       "   111         9      99216.0  11024.0      9.1                  data, centroids[np.newaxis, i - 1], self.distance)\n",
       "   112         9        753.0     83.7      0.1              nans = np.isnan(current_distance)\n",
       "   113         9        687.0     76.3      0.1              if np.any(nans):\n",
       "   114                                                           locations_of_nans = np.array(list(zip(*np.nonzero(nans))))\n",
       "   115                                                           raise ValueError('Distances between points cannot be NaN. '\n",
       "   116                                                                            + 'This indicates that your data is probably'\n",
       "   117                                                                            + ' corrupted and analysis cannot be '\n",
       "   118                                                                            + 'continued in this setting. '\n",
       "   119                                                                            + 'Amount of NaNs: {0}. '.format(nans.sum())\n",
       "   120                                                                            + 'At positions described by [spot, '\n",
       "   121                                                                            + 'centroid]: {0}'.format(locations_of_nans))\n",
       "   122         9       5265.0    585.0      0.5              distances[:] = np.minimum(current_distance.ravel(), distances)\n",
       "   123         9      15752.0   1750.2      1.4              selected = self._get_percentile_element(distances)\n",
       "   124         9         54.0      6.0      0.0              centroids[i] = data[selected]\n",
       "   125                                           \n",
       "   126         1          1.0      1.0      0.0          return centroids"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun \\\n",
    "    -f divik.cluster._kmeans._initialization.PercentileInitialization.__call__ \\\n",
    "    -f divik.cluster._kmeans._initialization._find_residuals \\\n",
    "    kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:12<00:12, 12.13s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:19<00:00, 10.69s/it]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [00:00<00:01,  6.76it/s]\u001b[A\n",
      " 22%|██▏       | 2/9 [00:00<00:01,  6.89it/s]\u001b[A\n",
      " 33%|███▎      | 3/9 [00:00<00:00,  6.83it/s]\u001b[A\n",
      " 44%|████▍     | 4/9 [00:00<00:00,  6.67it/s]\u001b[A\n",
      " 56%|█████▌    | 5/9 [00:00<00:00,  6.32it/s]\u001b[A\n",
      " 67%|██████▋   | 6/9 [00:00<00:00,  6.08it/s]\u001b[A\n",
      " 78%|███████▊  | 7/9 [00:01<00:00,  5.36it/s]\u001b[A\n",
      " 89%|████████▉ | 8/9 [00:01<00:00,  5.18it/s]\u001b[A\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.34it/s]\u001b[A\n",
      "                                             \u001b[A\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.44s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10000/100000 [00:31<04:45, 314.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.17s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20000/100000 [00:36<03:09, 421.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:02<00:02,  2.67s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30000/100000 [00:41<02:05, 557.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.44s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40000/100000 [00:51<01:34, 638.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:03<00:03,  3.81s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50000/100000 [00:57<01:03, 785.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.33s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60000/100000 [01:07<00:47, 834.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:07<00:07,  7.06s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70000/100000 [01:18<00:35, 855.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70000/100000 [01:30<00:35, 855.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80000/100000 [01:30<00:23, 857.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.37s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90000/100000 [01:37<00:10, 958.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.80s/it]\u001b[A\n",
      "                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:49<00:00, 909.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.826141 s\n",
       "File: /app/divik/cluster/_kmeans/_initialization.py\n",
       "Function: _find_residuals at line 37\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    37                                           def _find_residuals(data: Data) -> np.ndarray:\n",
       "    38       140        310.0      2.2      0.0      features = data.T\n",
       "    39       140        318.0      2.3      0.0      assumed_ys = features[0]\n",
       "    40       140       7099.0     50.7      0.9      modelled_xs = np.hstack([np.ones((data.shape[0], 1)),\n",
       "    41       140      53914.0    385.1      6.5                               features[1:].T])\n",
       "    42       140     706356.0   5045.4     85.5      coefficients = _lstsq_numba(modelled_xs, assumed_ys)\n",
       "    43       140      56853.0    406.1      6.9      residuals = _residuals_numba(modelled_xs, assumed_ys, coefficients)\n",
       "    44       140       1291.0      9.2      0.2      return residuals\n",
       "\n",
       "Total time: 1.41629 s\n",
       "File: /app/divik/cluster/_kmeans/_initialization.py\n",
       "Function: __call__ at line 99\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    99                                               def __call__(self, data: Data, number_of_centroids: int) -> Centroids:\n",
       "   100       140       1162.0      8.3      0.1          _validate(data, number_of_centroids)\n",
       "   101       140     855919.0   6113.7     60.4          residuals = _find_residuals(data)\n",
       "   102       140     104947.0    749.6      7.4          selected = self._get_percentile_element(residuals)\n",
       "   103       140       2072.0     14.8      0.1          centroids = np.nan * np.zeros((number_of_centroids, data.shape[1]))\n",
       "   104       140        659.0      4.7      0.0          centroids[0] = data[selected]\n",
       "   105       140       2788.0     19.9      0.2          assert not np.any(np.isnan(centroids[0]))\n",
       "   106                                           \n",
       "   107       140       5487.0     39.2      0.4          distances = np.inf * np.ones((data.shape[0],))\n",
       "   108       316        780.0      2.5      0.1          for i in range(1, number_of_centroids):\n",
       "   109       176       4095.0     23.3      0.3              assert not np.any(np.isnan(centroids[np.newaxis, i - 1]))\n",
       "   110       176        536.0      3.0      0.0              current_distance = dist.cdist(\n",
       "   111       176     271206.0   1540.9     19.1                  data, centroids[np.newaxis, i - 1], self.distance)\n",
       "   112       176       4879.0     27.7      0.3              nans = np.isnan(current_distance)\n",
       "   113       176       7817.0     44.4      0.6              if np.any(nans):\n",
       "   114                                                           locations_of_nans = np.array(list(zip(*np.nonzero(nans))))\n",
       "   115                                                           raise ValueError('Distances between points cannot be NaN. '\n",
       "   116                                                                            + 'This indicates that your data is probably'\n",
       "   117                                                                            + ' corrupted and analysis cannot be '\n",
       "   118                                                                            + 'continued in this setting. '\n",
       "   119                                                                            + 'Amount of NaNs: {0}. '.format(nans.sum())\n",
       "   120                                                                            + 'At positions described by [spot, '\n",
       "   121                                                                            + 'centroid]: {0}'.format(locations_of_nans))\n",
       "   122       176      36088.0    205.0      2.5              distances[:] = np.minimum(current_distance.ravel(), distances)\n",
       "   123       176     116794.0    663.6      8.2              selected = self._get_percentile_element(distances)\n",
       "   124       176        901.0      5.1      0.1              centroids[i] = data[selected]\n",
       "   125                                           \n",
       "   126       140        160.0      1.1      0.0          return centroids"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun \\\n",
    "    -f divik.cluster._kmeans._initialization.PercentileInitialization.__call__ \\\n",
    "    -f divik.cluster._kmeans._initialization._find_residuals \\\n",
    "    mdl.fit(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
